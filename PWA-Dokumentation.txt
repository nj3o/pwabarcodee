Einführung
Dieses Projekt bietet eine PWA (Progressive-Web-App) zur Barcode, Standort, Geräte und Texterkennung dar. 
Um Barcodes zu erkennen wurde die QuggaJS Library genommen, für die Texterkennung wird Tesseract.js verwendet. Diese Librarys sind schon eingebunden.
Die Anwendung zielt auf Mobile-Geräte, kann aber auch auf Laptop's/PC's verwendet werden.

*Die zwei Wichtigsten Links:*

Main: https://nj3o.github.io/pwabarcodee/pwa6_index.html

Test: https://nj3o.github.io/pwabarcodee/test.html

Unterstützte Browser	Unterstützte Geräte
-Google			-Android
-Edge			-Windows		
-Safari			-iPhone
			-iPad
			-iPod
			-Mac OS
			-Linux

Herunterladen

Klonen oder herunterladen aus dem Repository (https://github.com/nj3o/pwabarcodee)
Live-Server für pwa6_index.html aufrufen oder den Link (https://nj3o.github.io/pwabarcodee/pwa6_index.html) aufrufen

Verzeichnisstruktur

Hauptdateien, Hier sind die aktuellsten und funktionierenden Code-Dateien 
- pwa6_index.html
- style.css
- scripts.js

Testdateien, Können gebraucht werden um auszutesten ob der Code wie erwartet funktioniert
- test.html
- test.css
- test.js

Bilder und Sounds um die Icons darzustellen und den Sound zu importieren
- zoomin.png
- zoomout.png
- Switchcamera.png
- Scanbarcode.png
- Texterkennung_Piktogramm.png
- Standortsuchen.png
- beep.mp3

Funktionen

Initialisierung und Variablen:
const scanBarcodeBtn = document.getElementById('scanBarcodeBtn');
const refreshLocationBtn = document.getElementById('refreshLocationBtn');
const switchButton = document.getElementById('switchButton');
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const textArea = document.getElementById('textArea');
const resultElement = document.getElementById('result');
const userAgent = navigator.userAgent;
const os = getOS(userAgent);
let currentStream;
let codeReader;

operatingSystemDisplay.textContent = 'Operating System: ' + os;

Hier werden HTML-Elemente und wichtige Konstanten die im Skript verwendet werden initialisiert. "currentStream" speichert den aktuellen Video-Stram und "codeReader" wird für den Barcode-Leser verwendet.

Videoinitialisierung:
function startVideo(stream) {
    video.srcObject = stream;
    currentStream = stream;
}

Durch die "startVideo"-Fuktion wird der Video-Stream gestartet und wird im "video"-Element angezeigt. Im "currentStream" wird der Stream gespeichert um später darauf zugreifen zu können.

"isMobileDevice"-Funktion:
function isMobileDevice() {
    return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
}

Es wird geprüft ob das Gerät ein mobiles Gerät ist, indem der "userAgent" vom Browser untersucht wird.

function getOS(userAgent) {
    if (userAgent.match(/Android/i)) return 'Android';
    if (userAgent.match(/iPhone|iPad|iPod/i)) return 'iOS';
    if (userAgent.match(/Windows/i)) return 'Windows';
    if (userAgent.match(/Macintosh|Mac OS X/i)) return 'Mac OS';
    if (userAgent.match(/Linux/i)) return 'Linux';
    return 'Unbekannt';
}

Durch die "getOS" funktion wird nochmals überprüft ob es ein mobiles-Gerät ist, wenn ja wird in der Konsole etwas wiedergegeben.

Switchcamera-Buttonversteckfunktion:
function showButtonOnMobile(buttonId) {
    const button = document.getElementById(buttonId);
    if (isMobileDevice()) {
        button.style.display = 'block';
    } else {
        button.style.display = 'none';
    }
}

Stellt sicher, dass ein Button nur auf mobilen Geräten angezeigt wird.

Kameraeinstellungen:
async function initializeCamera() {
    const constraints = {
        audio: false,
        video: {
            facingMode: video.getAttribute('facing-mode') || 'environment'
        }
    };

    try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        startVideo(stream);
    } catch (err) {
        console.error('Error accessing camera:', err);
    }
}

"initializeCamera" sorgt dafür, dass zuerst die Rückkamera gesucht und gestartet wird, schliesslich sollte der VideoStream gestartet werden und funktionieren.

Bilderstellung für OCR:
function captureImageForOCR() {
    const context = canvas.getContext('2d');
    context.drawImage(video, 0, 0, canvas.width, canvas.height);
    const imageData = context.getImageData(0, 0, canvas.width, canvas.height);

    const noiseRemovedData = removeNoise(imageData);
    const binarizedData = binarizeImage(noiseRemovedData);
    context.putImageData(binarizedData, 0, 0);

    const imageDataUrl = canvas.toDataURL('image/png');

    if ('vibrate' in navigator) {
        navigator.vibrate([200]);
    }
    canvas.style.backgroundColor = '#ffcc00';

    Tesseract.recognize(
        imageDataUrl,
        'deu',
        {
            logger: m => console.log(m)
        }
    ).then(({ data: { text } }) => {
        textArea.value = text;
        canvas.style.backgroundColor = '';

        video.style.backgroundColor = 'lightgreen';
        setTimeout(() => {
            video.style.backgroundColor = '';
        }, 1000);

        const beepSound = document.getElementById('beepSound');
        beepSound.play();
    });
}

Es wird ein Bild erfasst vom Video-Stream. Schliesslich wird Rauschen entfernt, es wird binarisiert und führt dann eine Texterkennung durch.

function calculateDPI(width, height) {
    const screenWidthInches = window.screen.width / window.devicePixelRatio;
    const screenHeightInches = window.screen.height / window.devicePixelRatio;
    const diagonalInches = Math.sqrt(Math.pow(screenWidthInches, 2) + Math.pow(screenHeightInches, 2));
    return Math.max(width, height) / diagonalInches;
}

Berechnet die DPI des Bildes basierend an Bildschirmmassen.

function scaleImageTo300DPI(width, height) {
    const scaledWidth = (width / calculateDPI(width, height)) * 300;
    const scaledHeight = (height / calculateDPI(width, height)) * 300;
    const tempCanvas = document.createElement('canvas');
    tempCanvas.width = scaledWidth;
    tempCanvas.height = scaledHeight;
    tempCanvas.getContext('2d').drawImage(video, 0, 0, scaledWidth, scaledHeight);
    return tempCanvas;
}

Skaliert ein Bild auf 300 DPI.

function binarizeImage(imageData) {
    const threshold = 127; 
    const binaryData = new Uint8ClampedArray(imageData.data.length);
    for (let i = 0; i < imageData.data.length; i += 4) {
        const grayValue = (imageData.data[i] + imageData.data[i + 1] + imageData.data[i + 2]) / 3;
        const binaryValue = grayValue > threshold ? 255 : 0;
        binaryData[i] = binaryData[i + 1] = binaryData[i + 2] = binaryValue;
        binaryData[i + 3] = 255; 
    }
    return new ImageData(binaryData, imageData.width, imageData.height);
}

Hier wird das Bild in ein Schwarz/Weiss-Bild konvertiert, sodass es binarisiert werden kann basierend auf einem Schwellenwert.

function removeNoise(imageData) {
    const width = imageData.width;
    const height = imageData.height;
    const pixels = imageData.data;
    const output = new Uint8ClampedArray(pixels.length);

    function getPixel(x, y) {
        if (x < 0 || x >= width || y < 0 || y >= height) {
            return [255, 255, 255]; 
        }
        const index = (y * width + x) * 4;
        return [pixels[index], pixels[index + 1], pixels[index + 2]];
    }

    function median(values) {
        values.sort((a, b) => a - b);
        const middle = Math.floor(values.length / 2);
        return values.length % 2 !== 0 ? values[middle] : (values[middle - 1] + values[middle]) / 2;
    }

    for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
            const neighbors = [];
            for (let dy = -1; dy <= 1; dy++) {
                for (let dx = -1; dx <= 1; dx++) {
                    neighbors.push(getPixel(x + dx, y + dy));
                }
            }
            const reds = neighbors.map(p => p[0]);
            const greens = neighbors.map(p => p[1]);
            const blues = neighbors.map(p => p[2]);

            const index = (y * width + x) * 4;
            output[index] = median(reds);
            output[index + 1] = median(greens);
            output[index + 2] = median(blues);
            output[index + 3] = pixels[index + 3]; 
        }
    }

    return new ImageData(output, width, height);
}

Entfernt das Rauschen aus einem Bild mittels dem Median-Filter.

Barcodescanner:
function scanBarcode() {
    Quagga.init({
        inputStream: {
            name: "Live",
            type: "LiveStream",
            target: document.querySelector('#video'),
            constraints: {
                facingMode: "environment"
            },
        },
        decoder: {
            readers: ["code_128_reader", "ean_reader", "ean_8_reader", "code_39_reader", "codabar_reader", "upc_reader"]
        },
    }, function(err) {
        if (err) {
            console.log(err);
            return;
        }
        console.log("QuaggaJS initialisiert.");
        Quagga.start();
    });

    Quagga.onProcessed(function(result) {
        const drawingCtx = Quagga.canvas.ctx.overlay;
        const drawingCanvas = Quagga.canvas.dom.overlay;

        if (result) {
            if (result.boxes) {
                drawingCtx.clearRect(0, 0, drawingCanvas.width, drawingCanvas.height);
                result.boxes.filter(function(box) {
                    return box !== result.box;
                }).forEach(function(box) {
                    Quagga.ImageDebug.drawPath(box, { x: 0, y: 1 }, drawingCtx, {
                        color: "green",
                        lineWidth: 2
                    });
                });
            }

            if (result.box) {
                Quagga.ImageDebug.drawPath(result.box, { x: 0, y: 1 }, drawingCtx, {
                    color: "#00F",
                    lineWidth: 2
                });
            }

            if (result.codeResult && result.codeResult.code) {
                resultElement.innerText = `Barcode: ${result.codeResult.code}`;
            }
        }
    });

    Quagga.onDetected(function(result) {
        const code = result.codeResult.code;
        console.log(`Barcode erkannt: ${code}`);
        resultElement.innerText = `Erkannter Barcode: ${code}`;
    });
}

Hier wird QuaggaJS initialisiert, sodass Barcodes im Video-Stream erkennt werden.

Folgende Barcodes können gescannt werden:
"code_128_reader", "ean_reader", "ean_8_reader", "code_39_reader", "codabar_reader", "upc_reader"

Die erkannte Barcodenummer wird in einem grünen Kästchen angezeigt wenn sie erkannt wird. So kann man feststellen welche Barcodenummer es ist. Der Piepston bestimmt wann es gefunden worden ist.

Standorterkennung:
function fetchAndDisplayAddress(position) {
    const { latitude, longitude } = position.coords;
    const apiKey = 'b526254236ad47a1aebff6e137ad1790';
    const apiUrl = `https://api.opencagedata.com/geocode/v1/json?q=${latitude}+${longitude}&key=${apiKey}`;
    fetch(apiUrl)
        .then(response => response.json())
        .then(data => {
            const address = data.results.length > 0 ? data.results[0].formatted : 'Keine Adresse gefunden.';
            document.getElementById('locationDisplay').textContent = 'Adresse: ' + address;
        })
        .catch(() => {
            document.getElementById('locationDisplay').textContent = 'Adressabruf fehlgeschlagen.';
        });
}

Die "fetchAndDisplayAddress"- Funktion holt mithilfe der opencagedata-API die akutellen Geolocation-Daten, von dort aus wo der Button gedrückt wurde. Schlieslich wird es angezeigt als Addresse mit Nummer, Strasse und PLZ.

function showError(error) {
    document.getElementById('locationDisplay').textContent = 'Fehler: ' + error.message;
}

Zeigt Fehler an falls welche passieren.

Zoom-Funktion(Noah, weiss ned genau wie beschriebe mach du das bitte und schick mer denn de text, lueg der au min text für texterkennig ah bitte.)


Diese Dokumentation wurde von Nikola Mihic geschrieben. Bei Fragen bitte bei Noah Krip oder Nikola Mihic melden.
